---
layout: post
title: Putting Adafruit Uncanny Eyes on a Tube TV
date: 2021-05-03 12:30:00.000000000 +00:00
type: post
post_id: '26370'
parent_id: '0'
published: true
password: ''
status: publish
categories: []
tags:
- Composite Video
- ESP32
- ESP_8_BIT
- NTSC
meta:
  _last_editor_used_jetpack: block-editor
  _thumbnail_id: '26361'
  _oembed_14fff323938ea9507888d3a3e5cf2a8a: <div class="embed-twitter"><blockquote
    class="twitter-tweet" data-width="500" data-dnt="true"><p lang="en" dir="ltr">Hack
    and slashed <a href="https://twitter.com/adafruit?ref_src=twsrc%5Etfw">@adafruit</a>
    &quot;Uncanny Eyes&quot; sketch (Hallowing, Monster M4sk) to run on this rendering
    stack, now my tube TV stares back.<br><br>I&#39;ve also forgotten how hard it
    is to get a tube TV on video. Had to lock exposure all the way low to avoid bloomed
    out phosphors. <a href="https://t.co/qq5oc7l5zd">pic.twitter.com/qq5oc7l5zd</a></p>&mdash;
    Roger Cheng (@Regorlas) <a href="https://twitter.com/Regorlas/status/1384551877635809282?ref_src=twsrc%5Etfw">April
    20, 2021</a></blockquote><script async src="https://platform.twitter.com/widgets.js"
    charset="utf-8"></script></div>
  _oembed_time_14fff323938ea9507888d3a3e5cf2a8a: '1620190893'
  _oembed_00ea324763a6beb45de2e39dfaf24198: <div class="embed-twitter"><blockquote
    class="twitter-tweet" data-width="550" data-dnt="true"><p lang="en" dir="ltr">Hack
    and slashed <a href="https://twitter.com/adafruit?ref_src=twsrc%5Etfw">@adafruit</a>
    &quot;Uncanny Eyes&quot; sketch (Hallowing, Monster M4sk) to run on this rendering
    stack, now my tube TV stares back.<br><br>I&#39;ve also forgotten how hard it
    is to get a tube TV on video. Had to lock exposure all the way low to avoid bloomed
    out phosphors. <a href="https://t.co/qq5oc7l5zd">pic.twitter.com/qq5oc7l5zd</a></p>&mdash;
    Roger Cheng (@Regorlas) <a href="https://twitter.com/Regorlas/status/1384551877635809282?ref_src=twsrc%5Etfw">April
    20, 2021</a></blockquote><script async src="https://platform.twitter.com/widgets.js"
    charset="utf-8"></script></div>
  _publicize_job_id: '57925604870'
  timeline_notification: '1620070220'
  _oembed_84628482cfbb0b757be7a939ff316cc6: <div class="embed-twitter"><blockquote
    class="twitter-tweet" data-width="550" data-dnt="true"><p lang="en" dir="ltr">Hack
    and slashed <a href="https://twitter.com/adafruit?ref_src=twsrc%5Etfw">@adafruit</a>
    &quot;Uncanny Eyes&quot; sketch (Hallowing, Monster M4sk) to run on this rendering
    stack, now my tube TV stares back.<br><br>I&#39;ve also forgotten how hard it
    is to get a tube TV on video. Had to lock exposure all the way low to avoid bloomed
    out phosphors. <a href="https://t.co/qq5oc7l5zd">pic.twitter.com/qq5oc7l5zd</a></p>&mdash;
    Roger Cheng (@Regorlas) <a href="https://twitter.com/Regorlas/status/1384551877635809282?ref_src=twsrc%5Etfw">April
    20, 2021</a></blockquote><script async src="https://platform.twitter.com/widgets.js"
    charset="utf-8"></script></div>
  _oembed_time_84628482cfbb0b757be7a939ff316cc6: '1620070221'
  _oembed_13354be321fcfe7d3c99abc20b8a2e0e: <div class="embed-twitter"><blockquote
    class="twitter-tweet" data-width="550" data-dnt="true"><p lang="en" dir="ltr">Hack
    and slashed <a href="https://twitter.com/adafruit?ref_src=twsrc%5Etfw">@adafruit</a>
    &quot;Uncanny Eyes&quot; sketch (Hallowing, Monster M4sk) to run on this rendering
    stack, now my tube TV stares back.<br><br>I&#39;ve also forgotten how hard it
    is to get a tube TV on video. Had to lock exposure all the way low to avoid bloomed
    out phosphors. <a href="https://t.co/qq5oc7l5zd">pic.twitter.com/qq5oc7l5zd</a></p>&mdash;
    Roger Cheng (@Regorlas) <a href="https://twitter.com/Regorlas/status/1384551877635809282?ref_src=twsrc%5Etfw">April
    20, 2021</a></blockquote><script async src="https://platform.twitter.com/widgets.js"
    charset="utf-8"></script></div>
  _oembed_time_13354be321fcfe7d3c99abc20b8a2e0e: '1620070222'
  _oembed_time_00ea324763a6beb45de2e39dfaf24198: '1620070231'
  _oembed_15a689a27a4d0379dde8009368d8c84b: '<div class="embed-twitter"><blockquote
    class="twitter-tweet" data-width="500" data-dnt="true"><p lang="en" dir="ltr">Me:
    This 8-bit color chart sucks. I can make one that makes more sense. <br><br>Also
    me: <a href="https://t.co/i7uYBIbPya">pic.twitter.com/i7uYBIbPya</a></p>&mdash;
    Emily Velasco (@MLE_Online) <a href="https://twitter.com/MLE_Online/status/1386893522767286272?ref_src=twsrc%5Etfw">April
    27, 2021</a></blockquote><script async src="https://platform.twitter.com/widgets.js"
    charset="utf-8"></script></div>'
  _oembed_time_15a689a27a4d0379dde8009368d8c84b: '1620089015'
  _oembed_9274249dd1190d0ece07e7e340cfef93: <div class="embed-twitter"><blockquote
    class="twitter-tweet" data-width="500" data-dnt="true"><p lang="en" dir="ltr">HSV
    color cylinder with just 8-bit RGB332 colors. Original goal was to see if this
    can be flattened into a usable color chart in 2D. &quot;Just 256, how hard can
    it be?&quot; <a href="https://t.co/lsTQJTO6x8">pic.twitter.com/lsTQJTO6x8</a></p>&mdash;
    Roger Cheng (@Regorlas) <a href="https://twitter.com/Regorlas/status/1387533762225860610?ref_src=twsrc%5Etfw">April
    28, 2021</a></blockquote><script async src="https://platform.twitter.com/widgets.js"
    charset="utf-8"></script></div>
  _oembed_time_9274249dd1190d0ece07e7e340cfef93: '1620117449'
  _oembed_1a9c7b0e935655d71af1822abecbf533: <div class="embed-twitter"><blockquote
    class="twitter-tweet" data-width="550" data-dnt="true"><p lang="en" dir="ltr">Hack
    and slashed <a href="https://twitter.com/adafruit?ref_src=twsrc%5Etfw">@adafruit</a>
    &quot;Uncanny Eyes&quot; sketch (Hallowing, Monster M4sk) to run on this rendering
    stack, now my tube TV stares back.<br><br>I&#39;ve also forgotten how hard it
    is to get a tube TV on video. Had to lock exposure all the way low to avoid bloomed
    out phosphors. <a href="https://t.co/qq5oc7l5zd">pic.twitter.com/qq5oc7l5zd</a></p>&mdash;
    Roger Cheng (@Regorlas) <a href="https://twitter.com/Regorlas/status/1384551877635809282?ref_src=twsrc%5Etfw">April
    20, 2021</a></blockquote><script async src="https://platform.twitter.com/widgets.js"
    charset="utf-8"></script></div>
  _oembed_time_1a9c7b0e935655d71af1822abecbf533: '1708471183'
  _elasticsearch_data_sharing_indexed_on: '2024-11-18 13:29:46'
author:
  login: inkarc
  email: luxo.lamp@gmail.com
  display_name: Roger Cheng
  first_name: Roger
  last_name: Cheng
permalink: "/2021/05/03/putting-adafruit-uncanny-eyes-on-a-tube-tv/"
---
<p><!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"><br />
<!-- wp:paragraph --><html><body></p>
<p>I have <a href="https://newscrewdriver.com/2021/05/02/extracting-esp_8_bit-sega-color-video/">extracted the NTSC color composite video generation code</a> from rossumur's ESP_8_BIT project, and tested it by showing a static image. The obvious next step is to put something on screen that moves, and my test case is <a rel="noreferrer noopener" href="https://github.com/adafruit/Uncanny_Eyes" target="_blank">Adafruit's Uncanny Eyes</a> sketch. This is a nifty little display I encountered on <a rel="noreferrer noopener" href="https://newscrewdriver.com/2018/11/19/eyes-at-supercon-adafruit-hallowing/" target="_blank">Adafruit's Hallowing</a> and <a rel="noreferrer noopener" href="https://newscrewdriver.com/?s=Hallowing" target="_blank">used in a few projects</a> since. But even though I've <a rel="noreferrer noopener" href="https://newscrewdriver.com/2019/02/05/looking-under-the-hood-of-adafruit-spooky-eyes/" target="_blank">taken a peek at the code</a>, I've yet to try running that code on a different piece of hardware as I'm doing now.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>Originally written for a Teensy 3 and a particular display, <a rel="noreferrer noopener" href="https://github.com/adafruit/uncanny_eyes" target="_blank">Uncanny Eyes</a> has grown to support more microcontrollers and display modules including those on the Hallowing. It is now quite a complicated beast, littered with <code>#ifdef</code> sections blocking out code to support one component or another. It shows all the evidence of a project that has grown too unwieldy to easily evolve, which is probably why Adafruit has split into separate repositories for more advanced versions. There's <a rel="noreferrer noopener" href="https://github.com/adafruit/Adafruit_Learning_System_Guides/tree/master/M4_Eyes" target="_blank">one for Cortex-M4</a>, another <a rel="noreferrer noopener" href="https://github.com/adafruit/Pi_Eyes" target="_blank">one for Raspberry Pi</a>, and possibly others I haven't seen. In classic and admirable Adafruit fashion, all of these have corresponding detailed guides. Here's <a rel="noreferrer noopener" href="https://learn.adafruit.com/adafruit-monster-m4sk-eyes/compiling-from-source-code" target="_blank">the page for the Cortex-M4 eyes</a>, here's <a rel="noreferrer noopener" href="https://learn.adafruit.com/animated-snake-eyes-bonnet-for-raspberry-pi/software-installation" target="_blank">the page for Pi Eyes</a>, in addition to the <a rel="noreferrer noopener" href="https://learn.adafruit.com/animated-electronic-eyes/overview" target="_blank">Teensy/Hallowing M0 eyes</a> that got me started on this path.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>If my intent was to put together the best version I can on a TV, I would study all three variants. Read Adafruit documentation and review the code. But my intent is a quick proof of concept, so I pulled down the M0 version I was already familiar with from earlier study and started merrily hacking away. My objective was putting a moving eye on screen, and the key <code>drawEye()</code> method was easily adapted to write directly to my <code>_lines</code> frame buffer. This allowed me to cut out all code talking to a screen over SPI and such. This code had provisions for external interactivity such a joystick for controlling gaze direction, a button for blink, and a light sensor to adjust iris. I wanted a standalone demo and didn't care about that, and thankfully the code had provisions for a standalone demo. All I had to do was make sure a few things were <code>#define</code> (or not <code>#define</code>)-ed. That left a few places that were inconvenient to configure purely from <code>#define</code>, so I deleted them entirely for the purpose of the demo. They'll have to be fixed before interactivity can be restored in this code.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:embed {"url":"https:\/\/twitter.com\/Regorlas\/status\/1384551877635809282","type":"rich","providerNameSlug":"twitter","responsive":true} --></p>
<figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter">
<div class="wp-block-embed__wrapper">
https://twitter.com/Regorlas/status/1384551877635809282
</div>
</figure>
<p><!-- /wp:embed --></p>
<p><!-- wp:paragraph --></p>
<p>The code changes I had to make to enable this proof of concept is <a href="https://github.com/Roger-random/esp_ntsc_eye/commit/96244657714893f50a99e0b1cecc41f74bca88e8#diff-19dd5eb5c9fab5748c6f246095748cb5218c17fef96c0cdb74bf02daf1adf210">visible in this GitHub commit</a>. It successfully put a moving eye on my tube TV on my ESP32 using a composite video cable, running the color NTSC composite video generation code I pulled out of rossumur's ESP_8_BIT project. With the concept proven, I don't intend to polish or refine it. This was just a crude test run to see if these two pieces would work together. I set this project aside and moved on to <a href="https://wordpress.com/post/newscrewdriver.com/26370">other lessons I wanted to learn</a>.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph {"align":"center"} --></p>
<p class="has-text-align-center">[Code for this project is <a href="https://github.com/Roger-random/esp_ntsc_eye" target="_blank" rel="noreferrer noopener">publicly available on GitHub</a>]</p>
<p><!-- /wp:paragraph --><br />
</body></html></p>
