---
layout: post
title: Notes on "Deep Reinforcement Learning Doesn't Work Yet"
date: 2021-12-22 12:30:00.000000000 +00:00
type: post
post_id: '27974'
parent_id: '0'
published: true
password: ''
status: publish
categories:
- Investigations
tags:
- Reinforcement Learning
meta:
  _last_editor_used_jetpack: block-editor
  _thumbnail_id: '27975'
  _publicize_job_id: '66818299609'
  timeline_notification: '1640205040'
  _elasticsearch_data_sharing_indexed_on: '2024-11-18 13:30:38'
author:
  login: inkarc
  email: luxo.lamp@gmail.com
  display_name: Roger Cheng
  first_name: Roger
  last_name: Cheng
permalink: "/2021/12/22/notes-on-deep-reinforcement-learning-doesnt-work-yet/"
---
<p><!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"><br />
<!-- wp:paragraph --><html><body></p>
<p>OpenAI's guide <em>Spinning Up in Deep RL</em> has been very educational for me to read, even though I only understood a fraction of the information on my first pass through and I <a href="https://newscrewdriver.com/2021/12/21/notes-on-reinforcement-learning-algorithm-implementations-published-by-openai/">hardly understood the code examples</a> at all. But the true riches of this guide are in the links, so I faithfully followed the first link on the first page (<em><a rel="noreferrer noopener" href="https://spinningup.openai.com/en/latest/spinningup/spinningup.html" target="_blank">Spinning Up as a Deep RL Researcher</a></em>) of the Resources section and got a big wet towel dampening my enthusiasm.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p><em>Spinning Up</em>'s link text is "it's hard and it doesn't always work" and it led to Alex Irpan's blog post titled <em><a rel="noreferrer noopener" href="https://www.alexirpan.com/2018/02/14/rl-hard.html" target="_blank">Deep Reinforcement Learning Doesn't Work Yet</a></em>. The blog post covered all the RL pitfalls I've already learned about, either from <em>Spinning Up</em> or elsewhere, and added many more I hadn't known about. And boy, it paints a huge gap between the promise of reinforcement learning and what has actually been accomplished as of its publishing date almost four years ago in February 2018.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>The whole thing was a great read. At the end, my first question was: has the situation materially changed since its publishing in February 2018? As a beginner I have yet to learn of the sources that would help me confirm or disprove this post, so I started with the resource right at hand: the blog site this item was hosted on. Fortunately there weren't too many posts so I could quickly skim content of the past four years within a few hours. The author seems to still be involved in the field of reinforcement learning and would critique some notable papers during this time. But none seemed particularly earth-shattering.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>In the "<em>Doesn't Work Yet</em>" blog post, the author made references to ImageNet. (Eample quote: <em>Perception has gotten a lot better, but deep RL has yet to have its “ImageNet for control” moment.</em>) I believe this is referring to the ImageNet 2012 Challenge. Historically the top performers in this competition were separated by very narrow margins, but in 2012 <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/AlexNet" target="_blank">AlexNet</a> won with a margin of more than 10% using a GPU-trained convolutional neural network. This was one of the major events (sometimes credited as THE event) that kicked off the current wave of deep learning.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>So for robotics control systems, reinforcement learning has yet to see that kind of breakthrough. There have been many notable advancements, OpenAI themselves hyped a robot hand that <a rel="noreferrer noopener" href="https://openai.com/blog/solving-rubiks-cube/" target="_blank">could manipulate Rubik's Cube</a>. (Something Alex Irpan <a rel="noreferrer noopener" href="https://www.alexirpan.com/2019/10/29/openai-rubiks.html" target="_blank">has also written about</a>.) But looking under the covers, they've all had too many asterisks for the results to make a significant impact on real world applications. Researchers are making headway, but it's been a long tough slog for incremental advances.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>I appreciate OpenAI <em>Spinning Up</em> linking to the <em>Doesn't Work Yet</em> blog post. Despite all the promise and all the recent advances, there's still a <strong>long</strong> way to go. People new to the field need to have realistic expectations and maybe <a href="https://newscrewdriver.com/2021/12/23/switching-back-to-unity-ml-agents/">make adjustment to plans</a>.</p>
<p><!-- /wp:paragraph --><br />
</body></html></p>
